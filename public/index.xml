<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DYLAN WIWAD, Ph.D</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>DYLAN WIWAD, Ph.D</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>DYLAN WIWAD, Ph.D</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Example Page 1</title>
      <link>/courses/example/example1/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>/courses/example/example1/</guid>
      <description>&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Page 2</title>
      <link>/courses/example/example2/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>/courses/example/example2/</guid>
      <description>&lt;p&gt;Here are some more tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-3&#34;&gt;Tip 3&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-4&#34;&gt;Tip 4&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>/talk/example/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>/talk/example/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Academic&amp;rsquo;s 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further talk details can easily be added to this page using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/collaborators/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 -0500</pubDate>
      <guid>/collaborators/</guid>
      <description>&lt;DIV align=&#34;center&#34;&gt;
  &lt;h1&gt;My Collaborators&lt;/h1&gt;
&lt;/DIV&gt;
&lt;hr&gt;
&lt;DIV align=&#34;center&#34;&gt;
&lt;div class=figure&gt;&lt;img src=/files/nour.jpg width = 200 height = 100&gt;&lt;a href=&#34;https://www.kellogg.northwestern.edu/faculty/directory/kteily_nour.aspx&#34;&gt;&lt;h2&gt;Nour Kteily&lt;br&gt;Kellogg School of Management&lt;/h2&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div class=figure&gt;&lt;img src=/files/shai.jpeg width = 200 height = 100&gt;&lt;a href=&#34;https://www.shaidavidai.com/&#34;&gt;&lt;h2&gt;Shai Davidai&lt;br&gt;Columbia Business School&lt;/h2&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div class=figure&gt;&lt;img src=/files/nicole.jpg  width = 200 height = 100&gt;&lt;a href=&#34;https://www.kellogg.northwestern.edu/faculty/directory/stephens_nicole.aspx&#34;&gt;&lt;h2&gt;Nicole Stephens&lt;br&gt;Kellogg School of Management&lt;/h2&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div class=figure&gt;&lt;img src=/files/jon.jpeg width = 200 height = 100&gt;&lt;a href=&#34;https://sites.google.com/site/jonmjachimowicz/&#34;&gt;&lt;h2&gt;Jon Jachimowicz&lt;br&gt;Harvard Business School&lt;/h2&gt;&lt;/a&gt;&lt;/div&gt;
&lt;br&gt;
&lt;div class=figure&gt;&lt;img src=/files/lara.jpg width = 200 height = 100&gt;&lt;a href=&#34;http://www.sfu.ca/psychology/research/hhl/&#34;&gt;&lt;h2&gt;Lara Aknin&lt;br&gt;Simon Fraser University&lt;/h2&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div class=figure&gt;&lt;img src=/files/azim.jpg width = 200 height = 100&gt;&lt;a href=&#34;https://sharifflab.com/&#34;&gt;&lt;h2&gt;Azim Shariff&lt;br&gt;University of British Columbia&lt;/h2&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div class=figure&gt;&lt;img src=/files/paul.jpg width = 200 height = 100&gt;&lt;a href=&#34;https://paulpiff.wixsite.com/meshlab&#34;&gt;&lt;h2&gt;Paul Piff&lt;br&gt;University of California, Irvine&lt;/h2&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div class=figure&gt;&lt;img src=/files/brett.jpg width = 200 height = 100&gt;&lt;a href=&#34;https://www.brettmercier.com/&#34;&gt;&lt;h2&gt;Brett Mercier&lt;br&gt;University of California, Irvine&lt;/h2&gt;&lt;/a&gt;&lt;/div&gt;
&lt;/DIV&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/publications_citestyle/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 -0500</pubDate>
      <guid>/publications_citestyle/</guid>
      <description>&lt;DIV align=&#34;center&#34;&gt;
  &lt;h1&gt;My Research&lt;/h1&gt;
&lt;/DIV&gt;
&lt;p align = &#34;justify&#34;&gt;
My research identifies the key role that organizations play in understanding economic inequality: they not only create and maintain economic inequality but are also uniquely susceptible to many of the negative consequences that arise when economic inequality approaches unproductive levels (e.g., higher health care costs, higher employee turnover, unhappier and less productive workers). 
&lt;/p&gt;
&lt;p align = &#34;justify&#34;&gt;
In particular, my research has (i) uncovered various psychological mechanisms (e.g., income mobility, attributions for poverty) that legitimize inequality, (ii) tested how, when, and what interventions (e.g., perspective taking, cross-class contact) can promote egalitarian behavior and mitigate the negative consequences of economic inequality. 
&lt;/p&gt;
&lt;p&gt;You can see my full research statement 
&lt;a href=&#34;/files/research.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;DIV align=&#34;center&#34;&gt;
  &lt;h1&gt;Peer Reviewed Publications&lt;/h1&gt;
&lt;/DIV&gt;
&lt;DIV align=&#34;center&#34;&gt;
  &lt;h2&gt;2020&lt;/h2&gt;
&lt;/DIV&gt;
&lt;p&gt;&lt;strong&gt;Wiwad, D.&lt;/strong&gt;, Mercier, B., Piff. P. K., Aknin, L. B., Mercier, B., &amp;amp; Shariff, A. F. (2020). Recognizing the impact of COVID-19 on the poor alters attitudes towards poverty and inequality. &lt;em&gt;Journal of Experimental Social Psychology, 93&lt;/em&gt;, 104083. 
<<<<<<< HEAD:public/index.xml
&lt;a href=&#34;/files/jesp_2021.pdf&#34;&gt;doi.org/10.1016/j.jesp.2020.104083&lt;/a&gt;&lt;/p&gt;
=======
&lt;a href=&#34;https://dwiwad.github.io/files/jesp_2021.pdf&#34;&gt;doi.org/10.1016/j.jesp.2020.104083&lt;/a&gt;&lt;/p&gt;
>>>>>>> 2e85aaa64fa2c93ac8c107a9c8fdf3ec283dcb37:index.xml
&lt;p align=&#34;right&#34;&gt;&lt;a href=&#34;https://osf.io/8byzd/&#34;&gt;Data, Materials, and Code&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Piff. P. K*., &amp;amp; &lt;strong&gt;Wiwad, D.&lt;/strong&gt;*, Robinson, A. R., Aknin, L. B., Mercier, B., &amp;amp; Shariff, A. F. (2020). Shifting attributions for poverty motivates opposition to inequality and enhances egalitarianism. &lt;em&gt;Nature Human Behavior, 4&lt;/em&gt;, 496-505. 
&lt;a href=&#34;/files/nhb_2020.pdf&#34;&gt;doi.org/10.1038/s41562-020-0835-8&lt;/a&gt;&lt;/p&gt;
&lt;p align=&#34;right&#34;&gt;&lt;a href=&#34;https://osf.io/s8f7r/&#34;&gt;Data, Materials, and Code&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Mercier, B., &lt;strong&gt;Wiwad, D.&lt;/strong&gt;, Aknin, L. B., Piff, P. K., &amp;amp; Shariff, A. F. (2020). Does belief in free will increase support for economic inequality? &lt;em&gt;Collabra: Psychology, 6&lt;/em&gt;, 25. 
&lt;a href=&#34;/files/collabra_2020.pdf&#34;&gt;doi.org/10.1525/Collabra.303&lt;/a&gt;&lt;/p&gt;
&lt;p align=&#34;right&#34;&gt;&lt;a href=&#34;https://osf.io/zmygv/&#34;&gt;Data, Materials, and Code&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;DIV align=&#34;center&#34;&gt;
  &lt;h2&gt;2019&lt;/h2&gt;
&lt;/DIV&gt;
&lt;p&gt;&lt;strong&gt;Wiwad, D.&lt;/strong&gt;, Mercier, B., Maraun, M. D., Robinson, A. R., Piff, P. K., Aknin, L. B., &amp;amp; Shariff, A. F. (2019). The support for economic inequality scale: Development and adjudication. &lt;em&gt;PLoS ONE, 14&lt;/em&gt;, e0218685. 
&lt;a href=&#34;/files/plos_2019.pdf&#34;&gt;doi.org/10.1371/journal.pone.0218685&lt;/a&gt;&lt;/p&gt;
&lt;p align=&#34;right&#34;&gt;&lt;a href=&#34;https://osf.io/cmzye/&#34;&gt;Data, Materials, and Code&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Aknin, L. B., &lt;strong&gt;Wiwad, D.&lt;/strong&gt;, &amp;amp; Girme, Y. U. (2019). Not all gifts are good: The potential practical costs of motivated gifts. &lt;em&gt;Journal of Applied Social Psychology, 49&lt;/em&gt;, 75-85. 
&lt;a href=&#34;/files/jasp_2019.pdf&#34;&gt;doi.org/10.1111/jasp.12566&lt;/a&gt;&lt;/p&gt;
&lt;p align=&#34;right&#34;&gt;&lt;a href=&#34;https://osf.io/jnyfz/&#34;&gt;Data, Materials, and Code&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;DIV align=&#34;center&#34;&gt;
  &lt;h2&gt;2018&lt;/h2&gt;
&lt;/DIV&gt;
&lt;p&gt;Aknin, L. B., &lt;strong&gt;Wiwad, D.&lt;/strong&gt;, &amp;amp; Hanniball, K. (2018). Buying well-being: Spending behavior and happiness. &lt;em&gt;Social and Personality Psychology Compass, 12&lt;/em&gt;, e12386. 
&lt;a href=&#34;/files/sppc_2018.pdf&#34;&gt;doi.org/10.1111/spc3.12386&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;DIV align=&#34;center&#34;&gt;
  &lt;h2&gt;2017&lt;/h2&gt;
&lt;/DIV&gt;
&lt;p&gt;&lt;strong&gt;Wiwad, D.&lt;/strong&gt;, Aknin, L. B. (2017). Motives matter: The emotional consequences of recalled self- and other focused prosocial behavior. &lt;em&gt;Motivation and Emotion, 41&lt;/em&gt;,  730-740. 
&lt;a href=&#34;/files/motive_2017.pdf&#34;&gt;doi.org/10.1007/s11031-017-9638-2&lt;/a&gt;&lt;/p&gt;
&lt;p align=&#34;right&#34;&gt;&lt;a href=&#34;https://osf.io/4syj6/&#34;&gt;Data, Materials, and Code&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;DIV align=&#34;center&#34;&gt;
  &lt;h2&gt;2016&lt;/h2&gt;
&lt;/DIV&gt;
&lt;p&gt;Shariff, A. F., &lt;strong&gt;Wiwad, D.&lt;/strong&gt;, &amp;amp; Aknin, L. B. (2016). Income mobility breeds tolerance for economic
inequality: Cross-national and experimental evidence. &lt;em&gt;Perspectives on Psychological Science, 11&lt;/em&gt;,
373-380. 
&lt;a href=&#34;/files/pops_2016.pdf&#34;&gt;doi.org/10.1177/1745691616635596&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/teaching/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 -0500</pubDate>
      <guid>/teaching/</guid>
      <description>&lt;DIV align=&#34;center&#34;&gt;
  &lt;h1&gt;Teaching Philosophy&lt;/h1&gt;
&lt;/DIV&gt;
&lt;p align=&#34;justify&#34;&gt;
My goal when teaching is not only to foster a meaningful understanding of course content, but to ensure that students leave the classroom with knowledge they can confidently and successfully apply to their own lives. Over five years of teaching undergraduates at Simon Fraser University, and the past year of teaching MBA students at Kellogg School of Management, I have developed the two core philosophies of Learning by Doing and Inclusive Teaching in service of this goal. 
&lt;/p&gt;
&lt;p&gt;You can see my full teaching philosophy 
&lt;a href=&#34;/files/Teaching_Phil.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;DIV align=&#34;center&#34;&gt;
  &lt;h1&gt;Courses Taught&lt;/h1&gt;
&lt;/DIV&gt;
&lt;h2 id=&#34;kellogg-school-of-management&#34;&gt;Kellogg School of Management&lt;/h2&gt;
&lt;div style=&#34;padding-left: 2em;&#34;&gt;&lt;a href=&#34;/files/negotiations_syllabus.pdf&#34;&gt;Negotiation Fundamentals, Part-Time MBA, Summer 2020&lt;/a&gt;&lt;/div&gt;
&lt;h2 id=&#34;simon-fraser-university&#34;&gt;Simon Fraser University&lt;/h2&gt;
&lt;div style=&#34;padding-left: 2em;&#34;&gt;&lt;a href=&#34;/files/social_syllabus.pdf&#34;&gt;Introduction to Social Psychology, Winter 2019&lt;/a&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;DIV align=&#34;center&#34;&gt;
  &lt;h1&gt;TA Experience&lt;/h1&gt;
&lt;/DIV&gt;
&lt;h2 id=&#34;kellogg-school-of-management-1&#34;&gt;Kellogg School of Management&lt;/h2&gt;
&lt;div style=&#34;padding-left: 2em;&#34;&gt;Negotiations Fundamentals, Full Time MBA (2x), Spring 2020&lt;/div&gt;
&lt;h2 id=&#34;simon-fraser-university-1&#34;&gt;Simon Fraser University&lt;/h2&gt;
&lt;div style=&#34;padding-left: 2em;&#34;&gt;
Introduction to Social Psychology, Teaching Assistant (x6), 2013 - 2019&lt;br&gt;
Introduction to Data analysis in Psychology, Teaching Assistant (x2), 2014 - 2020&lt;br&gt;
Introduction to Research Methods, Teaching Assistant (x7), 2016 - 2020&lt;br&gt;
Psychology of Intergroup Relations, Teaching Assistant, Winter 2015 - Fall 2016&lt;br&gt;&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Coronavirus crisis may help Americans remember that economic inequality is not fair or just</title>
      <link>/project/latimes_covid/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/project/latimes_covid/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Why are the Poor Poor and Why Does it Matter?</title>
      <link>/project/nhb_behindthepaper/</link>
      <pubDate>Mon, 16 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/project/nhb_behindthepaper/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Shifting attributions for poverty motivates opposition to inequality and enhances egalitarianism</title>
      <link>/publication/nhb_2020/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/publication/nhb_2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Writing technical content in Academic</title>
      <link>/post/writing-technical-content/</link>
      <pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/post/writing-technical-content/</guid>
      <description>&lt;p&gt;Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Highlight your code snippets, take notes on math classes, and draw diagrams from textual representation.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Academic.&lt;/p&gt;
&lt;h2 id=&#34;examples&#34;&gt;Examples&lt;/h2&gt;
&lt;h3 id=&#34;code&#34;&gt;Code&lt;/h3&gt;
&lt;p&gt;Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the &lt;code&gt;highlight&lt;/code&gt; option in your &lt;code&gt;config/_default/params.toml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;math&#34;&gt;Math&lt;/h3&gt;
&lt;p&gt;Academic supports a Markdown extension for $\LaTeX$ math. You can enable this feature by toggling the &lt;code&gt;math&lt;/code&gt; option in your &lt;code&gt;config/_default/params.toml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;$...$&lt;/code&gt; or &lt;code&gt;$$...$$&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-tex&#34;&gt;$$\gamma_{n} = \frac{ 
\left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T 
\left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}
{\left \|\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right \|^2}$$
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left |\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right |^2}$$&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;$\nabla F(\mathbf{x}_{n})$&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the &lt;code&gt;\\\\&lt;/code&gt; math linebreak:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-tex&#34;&gt;$$f(k;p_0^*) = \begin{cases} p_0^* &amp;amp; \text{if }k=1, \\\\
1-p_0^* &amp;amp; \text {if }k=0.\end{cases}$$
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;$$f(k;p_0^*) = \begin{cases} p_0^* &amp;amp; \text{if }k=1, \\&lt;br&gt;
1-p_0^* &amp;amp; \text {if }k=0.\end{cases}$$&lt;/p&gt;
&lt;h3 id=&#34;diagrams&#34;&gt;Diagrams&lt;/h3&gt;
&lt;p&gt;Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the &lt;code&gt;diagram&lt;/code&gt; option in your &lt;code&gt;config/_default/params.toml&lt;/code&gt; file or by adding &lt;code&gt;diagram: true&lt;/code&gt; to your page front matter.&lt;/p&gt;
&lt;p&gt;An example &lt;strong&gt;flowchart&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
graph TD
A[Hard] --&amp;gt;|Text| B(Round)
B --&amp;gt; C{Decision}
C --&amp;gt;|One| D[Result 1]
C --&amp;gt;|Two| E[Result 2]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD
A[Hard] --&amp;gt;|Text| B(Round)
B --&amp;gt; C{Decision}
C --&amp;gt;|One| D[Result 1]
C --&amp;gt;|Two| E[Result 2]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An example &lt;strong&gt;sequence diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
sequenceDiagram
Alice-&amp;gt;&amp;gt;John: Hello John, how are you?
loop Healthcheck
    John-&amp;gt;&amp;gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&amp;gt;&amp;gt;Alice: Great!
John-&amp;gt;&amp;gt;Bob: How about you?
Bob--&amp;gt;&amp;gt;John: Jolly good!
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;sequenceDiagram
Alice-&amp;gt;&amp;gt;John: Hello John, how are you?
loop Healthcheck
    John-&amp;gt;&amp;gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&amp;gt;&amp;gt;Alice: Great!
John-&amp;gt;&amp;gt;Bob: How about you?
Bob--&amp;gt;&amp;gt;John: Jolly good!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An example &lt;strong&gt;Gantt diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An example &lt;strong&gt;class diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
classDiagram
Class01 &amp;lt;|-- AveryLongClass : Cool
&amp;lt;&amp;lt;interface&amp;gt;&amp;gt; Class01
Class09 --&amp;gt; C2 : Where am i?
Class09 --* C3
Class09 --|&amp;gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
class Class10 {
  &amp;lt;&amp;lt;service&amp;gt;&amp;gt;
  int id
  size()
}
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;classDiagram
Class01 &amp;lt;|-- AveryLongClass : Cool
&amp;lt;&amp;lt;interface&amp;gt;&amp;gt; Class01
Class09 --&amp;gt; C2 : Where am i?
Class09 --* C3
Class09 --|&amp;gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
class Class10 {
  &amp;lt;&amp;lt;service&amp;gt;&amp;gt;
  int id
  size()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An example &lt;strong&gt;state diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
stateDiagram
[*] --&amp;gt; Still
Still --&amp;gt; [*]
Still --&amp;gt; Moving
Moving --&amp;gt; Still
Moving --&amp;gt; Crash
Crash --&amp;gt; [*]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;stateDiagram
[*] --&amp;gt; Still
Still --&amp;gt; [*]
Still --&amp;gt; Moving
Moving --&amp;gt; Still
Moving --&amp;gt; Crash
Crash --&amp;gt; [*]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;todo-lists&#34;&gt;Todo lists&lt;/h3&gt;
&lt;p&gt;You can even write your todo lists in Academic too:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;- [x] Write math example
- [x] Write diagram example
- [ ] Do something else
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write math example&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write diagram example&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Do something else&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tables&#34;&gt;Tables&lt;/h3&gt;
&lt;p&gt;Represent your data in tables:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;| First Header  | Second Header |
| ------------- | ------------- |
| Content Cell  | Content Cell  |
| Content Cell  | Content Cell  |
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;First Header&lt;/th&gt;
&lt;th&gt;Second Header&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;asides&#34;&gt;Asides&lt;/h3&gt;
&lt;p&gt;Academic supports a 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/#alerts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcode for asides&lt;/a&gt;, also referred to as &lt;em&gt;notices&lt;/em&gt;, &lt;em&gt;hints&lt;/em&gt;, or &lt;em&gt;alerts&lt;/em&gt;. By wrapping a paragraph in &lt;code&gt;{{% alert note %}} ... {{% /alert %}}&lt;/code&gt;, it will render as an aside.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% alert note %}}
A Markdown aside is useful for displaying notices, hints, or definitions to your readers.
{{% /alert %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    A Markdown aside is useful for displaying notices, hints, or definitions to your readers.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;spoilers&#34;&gt;Spoilers&lt;/h3&gt;
&lt;p&gt;Add a spoiler to a page to reveal text, such as an answer to a question, after a button is clicked.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; spoiler text=&amp;quot;Click to view the spoiler&amp;quot; &amp;gt;}}
You found me!
{{&amp;lt; /spoiler &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;spoiler &#34; &gt;
  &lt;p&gt;
    &lt;a class=&#34;btn btn-primary&#34; data-toggle=&#34;collapse&#34; href=&#34;#spoiler-1&#34; role=&#34;button&#34; aria-expanded=&#34;false&#34; aria-controls=&#34;spoiler-1&#34;&gt;
      Click to view the spoiler
    &lt;/a&gt;
  &lt;/p&gt;
  &lt;div class=&#34;collapse card &#34; id=&#34;spoiler-1&#34;&gt;
    &lt;div class=&#34;card-body&#34;&gt;
      You found me!
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;icons&#34;&gt;Icons&lt;/h3&gt;
&lt;p&gt;Academic enables you to use a wide range of 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/page-builder/#icons&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;icons from &lt;em&gt;Font Awesome&lt;/em&gt; and &lt;em&gt;Academicons&lt;/em&gt;&lt;/a&gt; in addition to 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/#emojis&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;emojis&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here are some examples using the &lt;code&gt;icon&lt;/code&gt; shortcode to render icons:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; icon name=&amp;quot;terminal&amp;quot; pack=&amp;quot;fas&amp;quot; &amp;gt;}} Terminal  
{{&amp;lt; icon name=&amp;quot;python&amp;quot; pack=&amp;quot;fab&amp;quot; &amp;gt;}} Python  
{{&amp;lt; icon name=&amp;quot;r-project&amp;quot; pack=&amp;quot;fab&amp;quot; &amp;gt;}} R
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-terminal  pr-1 fa-fw&#34;&gt;&lt;/i&gt; Terminal&lt;br&gt;

  &lt;i class=&#34;fab fa-python  pr-1 fa-fw&#34;&gt;&lt;/i&gt; Python&lt;br&gt;

  &lt;i class=&#34;fab fa-r-project  pr-1 fa-fw&#34;&gt;&lt;/i&gt; R&lt;/p&gt;
&lt;h3 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title>Display Jupyter Notebooks with Academic</title>
      <link>/post/jupyter/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/post/jupyter/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from IPython.core.display import Image
Image(&#39;https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_1_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(&amp;quot;Welcome to Academic!&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Welcome to Academic!
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;install-python-and-jupyterlab&#34;&gt;Install Python and JupyterLab&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.anaconda.com/distribution/#download-section&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Install Anaconda&lt;/a&gt; which includes Python 3 and JupyterLab.&lt;/p&gt;
&lt;p&gt;Alternatively, install JupyterLab with &lt;code&gt;pip3 install jupyterlab&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;create-or-upload-a-jupyter-notebook&#34;&gt;Create or upload a Jupyter notebook&lt;/h2&gt;
&lt;p&gt;Run the following commands in your Terminal, substituting &lt;code&gt;&amp;lt;MY-WEBSITE-FOLDER&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;SHORT-POST-TITLE&amp;gt;&lt;/code&gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p &amp;lt;MY-WEBSITE-FOLDER&amp;gt;/content/post/&amp;lt;SHORT-POST-TITLE&amp;gt;/
cd &amp;lt;MY-WEBSITE-FOLDER&amp;gt;/content/post/&amp;lt;SHORT-POST-TITLE&amp;gt;/
jupyter lab index.ipynb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;jupyter&lt;/code&gt; command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.&lt;/p&gt;
&lt;h2 id=&#34;edit-your-post-metadata&#34;&gt;Edit your post metadata&lt;/h2&gt;
&lt;p&gt;The first cell of your Jupter notebook will contain your post metadata (
&lt;a href=&#34;https://sourcethemes.com/academic/docs/front-matter/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;front matter&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In Jupter, choose &lt;em&gt;Markdown&lt;/em&gt; as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
title: My post&#39;s title
date: 2019-09-01

# Put any other Academic metadata here...
---
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Edit the metadata of your post, using the 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt; as a guide to the available options.&lt;/p&gt;
&lt;p&gt;To set a 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#featured-image&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;featured image&lt;/a&gt;, place an image named &lt;code&gt;featured&lt;/code&gt; into your post&amp;rsquo;s folder.&lt;/p&gt;
&lt;p&gt;For other tips, such as using math, see the guide on 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;writing content with Academic&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;convert-notebook-to-markdown&#34;&gt;Convert notebook to Markdown&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;example&#34;&gt;Example&lt;/h2&gt;
&lt;p&gt;This post was created with Jupyter. The orginal files can be found at &lt;a href=&#34;https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter&#34;&gt;https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-academic&#34;&gt;Create slides in Markdown with Academic&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic&lt;/a&gt; | 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://spectrum.chat/academic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TBT Our SPSP 2015 Symposium on Economic Mobility and Inequality</title>
      <link>/project/spsp_2015/</link>
      <pubDate>Wed, 17 Oct 2018 00:00:00 -0500</pubDate>
      <guid>/project/spsp_2015/</guid>
      <description>&lt;p&gt;Back in 2015, when I was a second year Master&amp;rsquo;s student I co-chaired a symposium at the annual Society for Personality and Social Psychology (SPSP) conference with 
&lt;a href=&#34;https://www.shaidavidai.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Shai Davidai&lt;/a&gt;. In short, across three great talks given by Drs. Mike Norton and Shai Davidai, as well as myself, we covered:&lt;/p&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;High economic inequality is often justified by the belief in social mobility, the possibility that
anyone can increase their economic standing through hard work. Three speakers discuss new
research on subjective perceptions of inequality and social mobility, and the how these
perceptions impact emotional well-being.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;p&gt;We were lucky enough to have videographers at SPSP film each of the talks and post them on youtube. So, I thought I would archive them here with their abstracts. Take a trip back to SPSP of (almost) four years ago (!!) and see some of the cutting edge work on economic inequality and mobility.&lt;/p&gt;
&lt;h1 id=&#34;dr-mike-norton&#34;&gt;Dr. Mike Norton&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.hbs.edu/faculty/Pages/profile.aspx?facId=326229&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mike&amp;rsquo;s&lt;/a&gt; talk was titled &amp;ldquo;How Much (More) Should CEOs Make? A Universal Desire for More Equal Pay&amp;rdquo; and was based on 
&lt;a href=&#34;http://journals.sagepub.com/doi/abs/10.1177/1745691614549773&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; paper. Here is the abstract for the talk:&lt;/p&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;We assess people&#39;s preferred wage differentials between rich and poor, and determine whether
these ideal ratios are commonly-held. Using survey data from 40 countries (N = 55,238), we
compare respondents&#39; estimates of the actual wages of chief executive officers and unskilled
workers to their ideals for what those wages should be. We show that ideal pay gaps between
CEOs and unskilled workers are significantly smaller than estimated pay gaps, and that there is
consensus across countries, socioeconomic status, and political beliefs for ideal pay ratios.
Moreover, data from 16 countries reveals that people dramatically underestimate actual  pay
inequality. In the United States the actual pay ratio of CEOs to unskilled workers (354:1) far
exceeded the estimated ratio (30:1) which in turn far exceeded the ideal ratio (7:1). People
underestimate pay gaps, and their ideal pay gaps are even further from reality than their
erroneous underestimates.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/lHHetZogA34&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h1 id=&#34;dr-shai-davidai&#34;&gt;Dr. Shai Davidai&lt;/h1&gt;
&lt;p&gt;Shai&amp;rsquo;s talk was titled &amp;ldquo;Building a More Mobile America – One Income Quintile at a Time&amp;rdquo; and was based on 
&lt;a href=&#34;http://journals.sagepub.com/doi/abs/10.1177/1745691614562005&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; paper. Here is the abstract for the talk:&lt;/p&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;A core tenet of the American ethos is that there is considerable economic mobility. Americans
seem willing to accept vast financial inequalities as long as they believe that everyone has the
opportunity to succeed. We examined whether people’s beliefs about the amount of economic
mobility in the United States conform to reality. In a nationally representative sample
(N=3,034), we found that: (1) people believe there is more upward mobility than downward
mobility, (2) people overestimate the amount of upward mobility and underestimate the amount
of downward mobility and (3) poorer individuals believe there is more mobility than richer ones.
An additional study (N=290) replicated these results and found that political affiliation
influences perceptions of mobility, with conservatives believing that the economic system is
more dynamic than liberals do. We discuss these findings in terms of system justification theory
and consider the implications for contemporary political debates in the United States.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/iZ8bgcOeCPQ&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h1 id=&#34;myself&#34;&gt;Myself&lt;/h1&gt;
&lt;p&gt;My talk was titled &amp;ldquo;Belief in high social mobility and emotional well-being&amp;rdquo; and was based on 
&lt;a href=&#34;http://summit.sfu.ca/item/15479&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the work that became my Master&amp;rsquo;s Thesis&lt;/a&gt;. Here is the abstract for the talk:&lt;/p&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;The American Dream posits that anyone can move between income levels, but recent reports
document that income mobility is at an all-time low (Chetty, Hendren, Kline, &amp;amp; Saez, 2013).
High levels of income mobility may offer economic advantages, but does perceived mobility
impact well-being? Past research provides conflicting hypotheses, suggesting both positive and
negative well-being outcomes (Diener, Lucas, &amp;amp; Oishi, 2002; Smith, Loewenstein, Jankovic, &amp;amp;
Ubel, 2009). In Study 1(n=100) participants who believed they had higher income mobility
reported higher positive affect and life satisfaction. In Study 2 (n=456) participants randomly
assigned to read about high (vs. low) income mobility reported higher positive, and lower
negative, affect. In Study 3 (n=435) we replicated Study 2 in a nationally representative sample.
Across all three studies emotional benefits persisted regardless of the participants’ income level.
These findings suggest there are emotional benefits to perceiving high income mobility,
regardless of current economic standing.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/lf_jReoh9No&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;the-end&#34;&gt;The End!&lt;/h2&gt;
&lt;p&gt;And that&amp;rsquo;s it for our 2015 symposium! I hope you enjoyed! Please feel free to reach out if you have any questions!&lt;/p&gt;
&lt;p&gt;Bonus: I chaired another symposium on inequality at SPSP 2017. An undergraduate student writer wrote a post about Shai&amp;rsquo;s talk on &amp;ldquo;The Great Gatsby Curve&amp;rdquo; 
&lt;a href=&#34;http://www.spsp.org/news-center/blog/overestimate-economic-mobility&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Maching Learning Tutorial: Predicting Car Prices with K-Nearest Neighbours (KNN) Regression</title>
      <link>/project/car_prices/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 -0500</pubDate>
      <guid>/project/car_prices/</guid>
      <description>&lt;h1 id=&#34;predicting-car-prices-with-knn-regression&#34;&gt;Predicting Car Prices with KNN Regression&lt;/h1&gt;
&lt;p&gt;In this brief tutorial I am going to run through how to build, implement, and cross-validate a simple k-nearest neighbours (KNN) regression model. Simply put, KNN model is a variant of simple linear regression wherein we utilize information about neighbouring data points to predict an unknown outcome. To put a more concrete spin on this, and use the name quite literally, we can think about this in the context of your next door neighbours. If the outcome I wanted to predict was your personal income and didn&amp;rsquo;t have any other information about you, besides where you live, I might be wise to just ask your next door neighbours. I might decide to run a real life 4-nearest neighbours test. The two houses to the right of yours have a household incomes of $65,000 and $90,000 respectively, and the two to the left $100,000 and $72,000. In the simplest possible fashion I would then just assume you make somewhere in the ballpark of what your neighbours make, take an average, and predict that you have a household income of $81,750.&lt;/p&gt;
&lt;p&gt;This is an extremely basic explanation of how KNN algorithms work. But how do we decide who someone&amp;rsquo;s &amp;ldquo;neighbours&amp;rdquo; are when we aren&amp;rsquo;t talking about literal neighbours? That is, how do we know what other observations are similar to our target? Enter: distance metrics. The most common distance metric in for knn regression problems is 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Euclidean_distance&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Euclidian distance&lt;/a&gt;. This isn&amp;rsquo;t meant to be an extremely math heavy tutorial, so suffice it to say that in running a knn model, for each and every observation in a data set where we want to predict an outcome we grab their k-nearest neighbours, as defined by a metric such as Euclidean distance, from the training set, look at their values for the main dependent variable, and predict the new value based on the neighbours (e.g., as an average in a regression problem, or a &amp;ldquo;majority vote&amp;rdquo; in a classification problem).&lt;/p&gt;
&lt;p&gt;KNN regression can be used for both classification (i.e., predicting a binary outcome) and regression (i.e., predicting a continuous outcome). The procedure for implementation is largely the same and in this post I&amp;rsquo;m going to focus on regression. Specifically, the question at hand is: &lt;strong&gt;can we predict how much a used car is going to sell for?&lt;/strong&gt; For this question I am going to utilize a data set from the 
&lt;a href=&#34;https://archive.ics.uci.edu/ml/datasets/automobile&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;machine learning repository at The University of California, Irvine&lt;/a&gt;. First up is to just take a brief look at what is actually in the dataset.&lt;/p&gt;
&lt;h2 id=&#34;brief-exploratory-analysis-and-cleaning&#34;&gt;Brief Exploratory Analysis and Cleaning&lt;/h2&gt;
&lt;p&gt;These data contain a ton of information on a lot of different cars. For the purposes of this tutorial, I&amp;rsquo;m just going to pull out a set of relevant columns and work with those.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd

# Need to specify the headers for this dataset
cols = [&amp;quot;symboling&amp;quot;, &amp;quot;normalized_losses&amp;quot;, &amp;quot;make&amp;quot;, &amp;quot;fuel_type&amp;quot;, &amp;quot;aspiration&amp;quot;,
       &amp;quot;num_doors&amp;quot;, &amp;quot;body_style&amp;quot;, &amp;quot;drive_wheels&amp;quot;, &amp;quot;engine_location&amp;quot;,
       &amp;quot;wheel_base&amp;quot;, &amp;quot;length&amp;quot;, &amp;quot;width&amp;quot;, &amp;quot;height&amp;quot;, &amp;quot;curb_weight&amp;quot;, &amp;quot;engine_type&amp;quot;,
       &amp;quot;num_cylinders&amp;quot;, &amp;quot;engine_size&amp;quot;, &amp;quot;fuel_system&amp;quot;, &amp;quot;bore&amp;quot;, &amp;quot;stroke&amp;quot;,
       &amp;quot;compression_ratio&amp;quot;, &amp;quot;horsepower&amp;quot;, &amp;quot;peak_rpm&amp;quot;, &amp;quot;city_mpg&amp;quot;, &amp;quot;highway_mpg&amp;quot;,
       &amp;quot;price&amp;quot;]
cars = pd.read_csv(&amp;quot;imports-85.data&amp;quot;, names=cols)
cars.dtypes

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;symboling              int64
normalized_losses     object
make                  object
fuel_type             object
aspiration            object
num_doors             object
body_style            object
drive_wheels          object
engine_location       object
wheel_base           float64
length               float64
width                float64
height               float64
curb_weight            int64
engine_type           object
num_cylinders         object
engine_size            int64
fuel_system           object
bore                  object
stroke                object
compression_ratio    float64
horsepower            object
peak_rpm              object
city_mpg               int64
highway_mpg            int64
price                 object
dtype: object
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, as you can see we&amp;rsquo;ve got 25 columns that might be informative in predicting a car&amp;rsquo;s sale price, ranging from both highway and city miles per gallon to the number of doors a car has. Let&amp;rsquo;s take a quick look at the first few rows of the data just so we can get a sense of how it actually looks.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cars.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;symboling&lt;/th&gt;
      &lt;th&gt;normalized_losses&lt;/th&gt;
      &lt;th&gt;make&lt;/th&gt;
      &lt;th&gt;fuel_type&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;horsepower&lt;/th&gt;
      &lt;th&gt;peak_rpm&lt;/th&gt;
      &lt;th&gt;city_mpg&lt;/th&gt;
      &lt;th&gt;highway_mpg&lt;/th&gt;
      &lt;th&gt;price&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;?&lt;/td&gt;
      &lt;td&gt;alfa-romero&lt;/td&gt;
      &lt;td&gt;gas&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;111&lt;/td&gt;
      &lt;td&gt;5000&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;13495&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;?&lt;/td&gt;
      &lt;td&gt;alfa-romero&lt;/td&gt;
      &lt;td&gt;gas&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;111&lt;/td&gt;
      &lt;td&gt;5000&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;16500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;?&lt;/td&gt;
      &lt;td&gt;alfa-romero&lt;/td&gt;
      &lt;td&gt;gas&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;154&lt;/td&gt;
      &lt;td&gt;5000&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;16500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;164&lt;/td&gt;
      &lt;td&gt;audi&lt;/td&gt;
      &lt;td&gt;gas&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;102&lt;/td&gt;
      &lt;td&gt;5500&lt;/td&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;13950&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;164&lt;/td&gt;
      &lt;td&gt;audi&lt;/td&gt;
      &lt;td&gt;gas&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;115&lt;/td&gt;
      &lt;td&gt;5500&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;17450&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 26 columns&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;To keep things simple and focus just on numeric columns without much feature engineering for now, it seems like we can use wheelbase, length, width, height, engine size, compression ratio, and city/highway mpr to predict price. Some of these predictors probably offer more information that others (miles per gallon is probably more informative of a car&amp;rsquo;s sale price than curb weight).&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;re probably going to want to use some of the other variables that aren&amp;rsquo;t numeric - they are likely also meaningful. So, right now we&amp;rsquo;ll deal with counting and seeing where our missing values are, as well as turning relevant columns numeric so we can actually use them. You will have noticed above that there were some questionmarks in the data - we just need to turn those into missing values. So I do this in the code below, then I select sex non-numeric columns that might be meaningful (normalized_losses, bore, stroke, horsepower, peak_rpm, and price) and turn them numeric. These ones are easy as they are actually numbers, they just are currently stored as objects.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np

cars = cars.replace(&#39;?&#39;, np.nan)

# Now lets make things numeric
num_vars = [&#39;normalized_losses&#39;, &amp;quot;bore&amp;quot;, &amp;quot;stroke&amp;quot;, &amp;quot;horsepower&amp;quot;, &amp;quot;peak_rpm&amp;quot;,
            &amp;quot;price&amp;quot;]

for i in num_vars:
    cars[i] = cars[i].astype(&#39;float64&#39;)
    
cars.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;symboling&lt;/th&gt;
      &lt;th&gt;normalized_losses&lt;/th&gt;
      &lt;th&gt;make&lt;/th&gt;
      &lt;th&gt;fuel_type&lt;/th&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;th&gt;horsepower&lt;/th&gt;
      &lt;th&gt;peak_rpm&lt;/th&gt;
      &lt;th&gt;city_mpg&lt;/th&gt;
      &lt;th&gt;highway_mpg&lt;/th&gt;
      &lt;th&gt;price&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;alfa-romero&lt;/td&gt;
      &lt;td&gt;gas&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;111.0&lt;/td&gt;
      &lt;td&gt;5000.0&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;13495.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;alfa-romero&lt;/td&gt;
      &lt;td&gt;gas&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;111.0&lt;/td&gt;
      &lt;td&gt;5000.0&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;16500.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;alfa-romero&lt;/td&gt;
      &lt;td&gt;gas&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;154.0&lt;/td&gt;
      &lt;td&gt;5000.0&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;16500.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;164.0&lt;/td&gt;
      &lt;td&gt;audi&lt;/td&gt;
      &lt;td&gt;gas&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;102.0&lt;/td&gt;
      &lt;td&gt;5500.0&lt;/td&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;13950.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;164.0&lt;/td&gt;
      &lt;td&gt;audi&lt;/td&gt;
      &lt;td&gt;gas&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;115.0&lt;/td&gt;
      &lt;td&gt;5500.0&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;17450.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;5 rows × 26 columns&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Everything looks good now - how many missing values do we have in the normalized losses column?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(&amp;quot;normalized losses: &amp;quot;, cars[&#39;normalized_losses&#39;].isnull().sum())
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;normalized losses:  41
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are 41 missing values in the normalized_losses column. Given there are only 205 rows, thats a decent chunk missing. I&amp;rsquo;m not sure this column is the most useful, so we&amp;rsquo;ll just not use this column in our analyses at all. Let&amp;rsquo;s take a look at our other numeric columns and see what the missing values are like. The below chunk just calculates the sum of missing values for each variable and displays that sum.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cars.isnull().sum()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;symboling             0
normalized_losses    41
make                  0
fuel_type             0
aspiration            0
num_doors             2
body_style            0
drive_wheels          0
engine_location       0
wheel_base            0
length                0
width                 0
height                0
curb_weight           0
engine_type           0
num_cylinders         0
engine_size           0
fuel_system           0
bore                  4
stroke                4
compression_ratio     0
horsepower            2
peak_rpm              2
city_mpg              0
highway_mpg           0
price                 4
dtype: int64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So it looks like most of our columns are pretty good, with only a couple missing values here and there. The most crucial one here is price, our dependent variable; there are four cars that don&amp;rsquo;t have prices. Given that the number of missing rows is, at most, about 2%, I&amp;rsquo;m just going to listwise delete any row that has a missing variable in any of these. I don&amp;rsquo;t like mean imputation as it is purely making up data.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll start with the price column because its the most important and I suspect the rows that are missing price are the same rows missing the other data as well. Here I just drop any rows that are missing price data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cars = cars.dropna(subset = [&#39;price&#39;])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now lets check the missing values again, just to be sure it worked correctly:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cars.isnull().sum()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;symboling             0
normalized_losses    37
make                  0
fuel_type             0
aspiration            0
num_doors             2
body_style            0
drive_wheels          0
engine_location       0
wheel_base            0
length                0
width                 0
height                0
curb_weight           0
engine_type           0
num_cylinders         0
engine_size           0
fuel_system           0
bore                  4
stroke                4
compression_ratio     0
horsepower            2
peak_rpm              2
city_mpg              0
highway_mpg           0
price                 0
dtype: int64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, I&amp;rsquo;ll do the same to listwise delete the other numeric columns.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cars = cars.dropna(subset = [&#39;bore&#39;, &#39;stroke&#39;, &#39;horsepower&#39;, &#39;peak_rpm&#39;])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we should have no missing data and be ready to go! The next step is to convert all the numeric columns into standardized z-scores. This is especially important if your variables are on drastically different scales. For instance here, horsepower is generally way up over 100 and miles per gallon is never more than about 45. So what I&amp;rsquo;ll do below is trim the dataset down just to the numeric columns, and then convert each of those columns into a z-score. Then, I save this into a new dataset called &amp;ldquo;normalized.&amp;rdquo; This is generally good practice because that way we retain our original dataset in case we need to go back to it.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cols = [&#39;wheel_base&#39;, &#39;length&#39;, &#39;width&#39;, &#39;height&#39;,
        &#39;curb_weight&#39;, &#39;engine_size&#39;, &#39;bore&#39;, &#39;stroke&#39;, &#39;horsepower&#39;,
        &#39;peak_rpm&#39;, &#39;city_mpg&#39;, &#39;highway_mpg&#39;, &#39;price&#39;]
cars = cars[cols]

normalized_cars = (cars - cars.mean()) / (cars.std())
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;modeling&#34;&gt;Modeling&lt;/h2&gt;
&lt;p&gt;Alright, onward into some modeling! We&amp;rsquo;ve got a nice clean data set full of numeric columns. The first thing I&amp;rsquo;m going to do is create a couple of univariate (i.e., just one predictor) models, just to see how informative certain predictors are. Now, in more traditionally academic regression contexts this would be akin to just running some linear regressions with individual predictors. For example, we might see how well highway miles per gallon &amp;ldquo;predicts&amp;rdquo; sale price on it&amp;rsquo;s own. Of course, in the academic context, when we say predict what we actually mean is &amp;ldquo;variance explained&amp;rdquo; - we&amp;rsquo;re really finding out how much of the variance in sale price can be explained just by looking at highway miles per gallon.&lt;/p&gt;
&lt;p&gt;In the machine learning context, we are actually more concerned with &lt;em&gt;prediction&lt;/em&gt;. That is, if we build a KNN model, where we were only identifying neighbours based on how similar they were in highway miles per gallon, could we accurately predict price? There are myriad different ways we could judge accuracy, but here I&amp;rsquo;m going to use 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Root-mean-square_deviation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Root Mean Squared Error (RMSE)&lt;/a&gt;. RMSE is one of the most common error metrics for regression based machine learning. Again, this is not meant to be a math-heavy tutorial so I won&amp;rsquo;t go into it deeply here but it quantifies how far off our predictions were from the actual values.&lt;/p&gt;
&lt;p&gt;So, to start running some very basic univariate KNN models I imported two pieces of the sklearn package below, one for training a KNN model (KNeighborsRegressor) and one for calculating the mean squared error (mean_squared_error), from which we will derive the RMSE. Now, we need to do a couple things to build these models. Specifically, we need to choose the predictor we want to test, choose the dependent variable, and split our data into training and test sets so we reduce the risk of 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Overfitting&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;overfitting&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To accomplish this, I define a function that takes in three arguments: (1) our training column(s), (2), our target column, and (3) the dataset to use. Using this information, the function first instatiates an instance of a k-nearest neighbours regression (stored as &amp;ldquo;knn&amp;rdquo;) and sets a set so our results are reproducible. Next, the function shuffles the data into a random order, splits the data in half, designates the top half as the training data, and the bottom half as the test data.&lt;/p&gt;
&lt;p&gt;Then, we get down to the nitty gritty. The function fits the knn object on the specified training and test columns of the training data, uses that model to make predictions on the test data, and then calculates the RMSE (e.g., the difference between the predictions our model made for each car in the test set&amp;rsquo;s price and the actual prices).&lt;/p&gt;
&lt;p&gt;As we move through, we&amp;rsquo;ll complicate this function bit by bit, adding extra stuff to it.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Writing a simple function that trains and tests univariate models
# This function takes in three arguments: the predictor, the outcome, &amp;amp; the data
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

def knn_train_test(train_col, target_col, df):
    knn = KNeighborsRegressor()
    np.random.seed(1)
        
    # Randomize order of rows in data frame.
    shuffled_index = np.random.permutation(df.index)
    rand_df = df.reindex(shuffled_index)

    # Divide number of rows in half and round.
    last_train_row = int(len(rand_df) / 2)
    
    # Select the first half and set as training set.
    # Select the second half and set as test set.
    train_df = rand_df.iloc[0:last_train_row]
    test_df = rand_df.iloc[last_train_row:]
    
    # Fit a KNN model using default k value.
    knn.fit(train_df[[train_col]], train_df[target_col])
    
    # Make predictions using model.
    predicted_labels = knn.predict(test_df[[train_col]])

    # Calculate and return RMSE.
    mse = mean_squared_error(test_df[target_col], predicted_labels)
    rmse = np.sqrt(mse)
    return rmse
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we&amp;rsquo;ve got this function defined, let&amp;rsquo;s use it! If you recall, I said I was going to just test some basic univariate models. So, I&amp;rsquo;m going to run our new function five times, getting the RMSE of five different predictors. I just chose four that I thought would be relatively meaningful in predicting price (city and highway miles per gallon, engine size, and horsepower) and one to serve as a logic check (width) - why would width predict the price of a car, unless larger vehicles are more expensive. In any case, my intuition suggests that width should be the word predictor of price.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Lets test a couple of predictors
print(&#39;city mpg: &#39;, knn_train_test(&#39;city_mpg&#39;, &#39;price&#39;, normalized_cars))
print(&#39;width: &#39;, knn_train_test(&#39;width&#39;, &#39;price&#39;, normalized_cars))
print(&#39;highway mpg: &#39;, knn_train_test(&#39;highway_mpg&#39;, &#39;price&#39;, normalized_cars))
print(&#39;engine size: &#39;, knn_train_test(&#39;engine_size&#39;, &#39;price&#39;, normalized_cars))
print(&#39;horsepower: &#39;, knn_train_test(&#39;horsepower&#39;, &#39;price&#39;, normalized_cars))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;city mpg:  0.598975486019
width:  0.671608148246
highway mpg:  0.537913994132
engine size:  0.536691465842
horsepower:  0.571585852136
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As I suspected, width is by quite a large margin the worst predictor of a car&amp;rsquo;s price. Of the couple predictors that I threw in there to test, the best most informative for determining a vehicles price seems to be it&amp;rsquo;s highway. So, if we wanted to be as accurate as possible while only using on predictor, we would want to use fuel economy on the highway.&lt;/p&gt;
&lt;h2 id=&#34;hyperparamaterization&#34;&gt;&amp;ldquo;Hyperparamaterization&amp;rdquo;&lt;/h2&gt;
&lt;p&gt;If you recall, in KNN regression, we can set k to be whatever we want: 3, 5, 7, 100, 1000. Common values of k range from 3 to 10 - does tweaking our k value, and grabbing more or less neighbours to make our price guess, make the model fit better? As a test of this question, I&amp;rsquo;m going to modify the above function to take another argument: a k value. Then, I&amp;rsquo;ll test each of the five predictors above (plus some more) each with five different values of k (1, 3, 5, 7, and 9). This will effectively run our regression 25 times; city mpg with 1 neighbour, city mpg with 2 neighbours, and so on.&lt;/p&gt;
&lt;p&gt;The way I&amp;rsquo;ve done this is to insert a list of k-values into the middle of the function, and set up an empty dictionary to store all our RMSEs. Then, I nested the code from previously that fits the model, generates our predictions, and calculates the RSME into a for loop that does this for each value of k. Lastly, it appends the RMSE to the dictionary and returns it.&lt;/p&gt;
&lt;p&gt;Lastly, I specified a list of all the columns I want to build univariate models for, use a for loop to run the function on each of those columns, and append the results to another dictionary called &amp;ldquo;k_rmse_results.&amp;rdquo; Printing this dictionary gives us the name of the predictor, the specified k, and then the RMSE.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def knn_train_test_new(train_col, target_col, df):
    np.random.seed(1)
        
    # Randomize order of rows in data frame.
    shuffled_index = np.random.permutation(df.index)
    rand_df = df.reindex(shuffled_index)

    # Divide number of rows in half and round.
    last_train_row = int(len(rand_df) / 2)
    
    # Select the first half and set as training set.
    # Select the second half and set as test set.
    train_df = rand_df.iloc[0:last_train_row]
    test_df = rand_df.iloc[last_train_row:]
    
    k_values = [1,3,5,7,9]
    k_rmses = {}
    
    for k in k_values:
        # Fit model using k nearest neighbors.
        knn = KNeighborsRegressor(n_neighbors=k)
        knn.fit(train_df[[train_col]], train_df[target_col])

        # Make predictions using model.
        predicted_labels = knn.predict(test_df[[train_col]])

        # Calculate and return RMSE.
        mse = mean_squared_error(test_df[target_col], predicted_labels)
        rmse = np.sqrt(mse)
        
        k_rmses[k] = rmse
    return k_rmses

k_rmse_results = {}

# For each column from above, train a model, return RMSE value
# and add to the dictionary `rmse_results`.
variables = [&#39;wheel_base&#39;, &#39;length&#39;, &#39;width&#39;, &#39;height&#39;,
        &#39;curb_weight&#39;, &#39;engine_size&#39;, &#39;bore&#39;, &#39;stroke&#39;, &#39;horsepower&#39;,
        &#39;peak_rpm&#39;, &#39;city_mpg&#39;, &#39;highway_mpg&#39;]

for var in variables:
    rmse_val = knn_train_test_new(var, &#39;price&#39;, normalized_cars)
    k_rmse_results[var] = rmse_val

k_rmse_results
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{&#39;bore&#39;: {1: 1.2142304178718561,
  3: 0.86766581048215152,
  5: 0.89458788943880752,
  7: 0.94676716177240661,
  9: 0.95385344053196963},
 &#39;city_mpg&#39;: {1: 0.69529747854104784,
  3: 0.59031417913396289,
  5: 0.59897548601904338,
  7: 0.59715938629269016,
  9: 0.57728649652220132},
 &#39;curb_weight&#39;: {1: 0.8365387787670262,
  3: 0.64395375801733934,
  5: 0.57031290606074236,
  7: 0.51644149986604171,
  9: 0.51839468763038343},
 &#39;engine_size&#39;: {1: 0.55456842477058543,
  3: 0.54125650939355474,
  5: 0.53669146584152094,
  7: 0.51899873944760311,
  9: 0.50362821678292591},
 &#39;height&#39;: {1: 1.1521894508998922,
  3: 1.0168354498989998,
  5: 0.94018342361170537,
  7: 0.98192402693779424,
  9: 0.94562106614391528},
 &#39;highway_mpg&#39;: {1: 0.69402405950428248,
  3: 0.57416390399142236,
  5: 0.53791399413219376,
  7: 0.53495996840130122,
  9: 0.54899088943686292},
 &#39;horsepower&#39;: {1: 0.54931712010379319,
  3: 0.58337889657418729,
  5: 0.57158585213578872,
  7: 0.59314672824644243,
  9: 0.59002690698940097},
 &#39;length&#39;: {1: 0.65713817747103875,
  3: 0.63950652453727652,
  5: 0.64700844560860649,
  7: 0.66892394999830362,
  9: 0.6572441270128111},
 &#39;peak_rpm&#39;: {1: 0.85899385207057188,
  3: 0.88634665981443039,
  5: 0.90984280257609562,
  7: 0.90757986581712302,
  9: 0.90022237747155309},
 &#39;stroke&#39;: {1: 0.91796375714948086,
  3: 0.88113492952413897,
  5: 0.89586641314603555,
  7: 0.94574853212680499,
  9: 0.92121730389055356},
 &#39;wheel_base&#39;: {1: 0.70984063675235898,
  3: 0.70981264790591259,
  5: 0.70662378566203043,
  7: 0.71073380297018984,
  9: 0.72499494497288963},
 &#39;width&#39;: {1: 0.77543242861316763,
  3: 0.68812005931548847,
  5: 0.67160814824580428,
  7: 0.5826291501627695,
  9: 0.56790774193128279}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Generally speaking, just eyeballing within each predictor, going up to k = 9 worked the best for some of the models, but not for others. The error actually went up as we increased k for some. With a k of 9, the best univariate predictor seems to be engine size, with predictions only off by about half a standard deviation. So thats the best so far, but it&amp;rsquo;s still not great. When trying to predict an outcome, univariate models aren&amp;rsquo;t going to be extremely informative. Outcomes are complex, so let&amp;rsquo;s build a model that reflects that and takes in more than one column.&lt;/p&gt;
&lt;p&gt;What I&amp;rsquo;ve done to accomplish this is modified the above function to take multiple columns and then train and test some models using the the best two, then three, four, and five columns from above. By eyeballing at the 5-nearest neighbours level, the columns that predict the best in isolation are engine size, highway mpg, curb_weight, horsepower, and city mpg.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def knn_train_test_mult(train_cols, target_col, df):
    np.random.seed(1)
        
    # Randomize order of rows in data frame.
    shuffled_index = np.random.permutation(df.index)
    rand_df = df.reindex(shuffled_index)

    # Divide number of rows in half and round.
    last_train_row = int(len(rand_df) / 2)
    
    # Select the first half and set as training set.
    # Select the second half and set as test set.
    train_df = rand_df.iloc[0:last_train_row]
    test_df = rand_df.iloc[last_train_row:]
    
    k_values = [5]
    k_rmses = {}
    
    for k in k_values:
        # Fit model using k nearest neighbors.
        knn = KNeighborsRegressor(n_neighbors=k)
        knn.fit(train_df[train_cols], train_df[target_col])

        # Make predictions using model.
        predicted_labels = knn.predict(test_df[train_cols])

        # Calculate and return RMSE.
        mse = mean_squared_error(test_df[target_col], predicted_labels)
        rmse = np.sqrt(mse)
        
        k_rmses[k] = rmse
    return k_rmses

train_cols_2 = [&#39;engine_size&#39;, &#39;highway_mpg&#39;]
train_cols_3 = [&#39;engine_size&#39;, &#39;highway_mpg&#39;, &#39;curb_weight&#39;]
train_cols_4 = [&#39;engine_size&#39;, &#39;highway_mpg&#39;, &#39;curb_weight&#39;,
               &#39;horsepower&#39;]
train_cols_5 = [&#39;engine_size&#39;, &#39;highway_mpg&#39;, &#39;curb_weight&#39;,
               &#39;horsepower&#39;, &#39;city_mpg&#39;]

k_rmse_results = {}

rmse_val = knn_train_test_mult(train_cols_2, &#39;price&#39;, normalized_cars)
k_rmse_results[&amp;quot;two best features&amp;quot;] = rmse_val
rmse_val = knn_train_test_mult(train_cols_3, &#39;price&#39;, normalized_cars)
k_rmse_results[&amp;quot;three best features&amp;quot;] = rmse_val
rmse_val = knn_train_test_mult(train_cols_4, &#39;price&#39;, normalized_cars)
k_rmse_results[&amp;quot;four best features&amp;quot;] = rmse_val
rmse_val = knn_train_test_mult(train_cols_5, &#39;price&#39;, normalized_cars)
k_rmse_results[&amp;quot;five best features&amp;quot;] = rmse_val

k_rmse_results
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{&#39;five best features&#39;: {5: 0.49634970383078636},
 &#39;four best features&#39;: {5: 0.48157162981314988},
 &#39;three best features&#39;: {5: 0.50707231602531166},
 &#39;two best features&#39;: {5: 0.43695579560820619}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, what we have here is four new models that combine the best features we identified above. For example, the two best features model is using engine size and highway mpg to predict sale price with k set to 5. The three best predictors model is using engine size, highway mpg, and curb weight. Interestingly, adding more predictors does not increase the performance of the model at all - in fact, it makes it worse. This is not at all surprising because we started with the two best predictors, and just tacked on worse and worse predictors. So simply adding more doesn&amp;rsquo;t do anything good for us, it just adds muddier predictors to the model.&lt;/p&gt;
&lt;p&gt;The best performing model here to predict the price of a car is simply it&amp;rsquo;s engine size and highway miles per gallon. Let&amp;rsquo;s combine the two tests we&amp;rsquo;ve done so far and go a little overboard with it. Let&amp;rsquo;s test are four multivariate models at all ks ranging from 1 to 25.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def knn_train_test_mult(train_cols, target_col, df):
    np.random.seed(1)
        
    # Randomize order of rows in data frame.
    shuffled_index = np.random.permutation(df.index)
    rand_df = df.reindex(shuffled_index)

    # Divide number of rows in half and round.
    last_train_row = int(len(rand_df) / 2)
    
    # Select the first half and set as training set.
    # Select the second half and set as test set.
    train_df = rand_df.iloc[0:last_train_row]
    test_df = rand_df.iloc[last_train_row:]
    
    k_values = list(range(1,25))
    k_rmses = {}
    
    for k in k_values:
        # Fit model using k nearest neighbors.
        knn = KNeighborsRegressor(n_neighbors=k)
        knn.fit(train_df[train_cols], train_df[target_col])

        # Make predictions using model.
        predicted_labels = knn.predict(test_df[train_cols])

        # Calculate and return RMSE.
        mse = mean_squared_error(test_df[target_col], predicted_labels)
        rmse = np.sqrt(mse)
        
        k_rmses[k] = rmse
    return k_rmses

k_rmse_results_2 = {}

rmse_val = knn_train_test_mult(train_cols_2, &#39;price&#39;, normalized_cars)
k_rmse_results_2[&amp;quot;two best features&amp;quot;] = rmse_val
rmse_val = knn_train_test_mult(train_cols_3, &#39;price&#39;, normalized_cars)
k_rmse_results_2[&amp;quot;three best features&amp;quot;] = rmse_val
rmse_val = knn_train_test_mult(train_cols_4, &#39;price&#39;, normalized_cars)
k_rmse_results_2[&amp;quot;four best features&amp;quot;] = rmse_val
rmse_val = knn_train_test_mult(train_cols_5, &#39;price&#39;, normalized_cars)
k_rmse_results_2[&amp;quot;five best features&amp;quot;] = rmse_val

k_rmse_results_2

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{&#39;five best features&#39;: {1: 0.48370851070283638,
  2: 0.45709593736092696,
  3: 0.45932846135166017,
  4: 0.47702516372024495,
  5: 0.49634970383078636,
  6: 0.51326367838750764,
  7: 0.49909158266517145,
  8: 0.49234720868686166,
  9: 0.49925986215124729,
  10: 0.50320132862625788,
  11: 0.49352187011331128,
  12: 0.50969596379759741,
  13: 0.51666729281793589,
  14: 0.52430330537451841,
  15: 0.52831175797337293,
  16: 0.53372729477563852,
  17: 0.53629514907736431,
  18: 0.53771760713738892,
  19: 0.54366780131360726,
  20: 0.55390626006954025,
  21: 0.56186625263562961,
  22: 0.56399228907515964,
  23: 0.56686293421110434,
  24: 0.56749133395228601},
 &#39;four best features&#39;: {1: 0.46011695087263338,
  2: 0.47254209382853879,
  3: 0.4957675847479055,
  4: 0.47457606714743178,
  5: 0.48157162981314988,
  6: 0.4988487989184765,
  7: 0.51321993316267744,
  8: 0.51485477394479984,
  9: 0.51767653423898286,
  10: 0.5323478616627898,
  11: 0.51621784291210482,
  12: 0.51180481420952084,
  13: 0.52093660357028182,
  14: 0.5264585716201885,
  15: 0.53375627848681184,
  16: 0.53867876043121632,
  17: 0.539751445854185,
  18: 0.54052905274747964,
  19: 0.54394381259000146,
  20: 0.55263828123323866,
  21: 0.55895871633176053,
  22: 0.56273074037859749,
  23: 0.55965116497813094,
  24: 0.56079209060485291},
 &#39;three best features&#39;: {1: 0.53304672541629627,
  2: 0.47236953984714419,
  3: 0.48544239785342919,
  4: 0.46468465687861726,
  5: 0.50707231602531166,
  6: 0.50672338800144279,
  7: 0.52042141176821866,
  8: 0.51959755832321974,
  9: 0.51531096459267978,
  10: 0.52080169867439063,
  11: 0.52322240088596494,
  12: 0.52075280982124794,
  13: 0.51183217030638006,
  14: 0.51868070682253542,
  15: 0.52774088364145721,
  16: 0.53035523273810814,
  17: 0.53183552745587126,
  18: 0.53451532836203997,
  19: 0.54155167597224763,
  20: 0.54551779898598018,
  21: 0.54674295619522062,
  22: 0.54707824469373634,
  23: 0.54985793303062935,
  24: 0.55512440029648535},
 &#39;two best features&#39;: {1: 0.4962211708123152,
  2: 0.42439666654800412,
  3: 0.37244955551446796,
  4: 0.38221587546513652,
  5: 0.43695579560820619,
  6: 0.49363489340281513,
  7: 0.50823941279743867,
  8: 0.51418965195989808,
  9: 0.52616341995960625,
  10: 0.53013621032483371,
  11: 0.53671709358748898,
  12: 0.53444184258976579,
  13: 0.51587142155192167,
  14: 0.51205713655316698,
  15: 0.5119686970820041,
  16: 0.51750488428455055,
  17: 0.52218955380387977,
  18: 0.53175784405886029,
  19: 0.54377416147308744,
  20: 0.54302569583633942,
  21: 0.54968364588915308,
  22: 0.5508362135961884,
  23: 0.55132842211110611,
  24: 0.55665088230669157}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can probably tell, it&amp;rsquo;s hard to make sense of this. For our different models with 2, 3, 4, and 5 predictors, what is the most accurate value of k? The best way to explore this might be just to plot it out! So, I&amp;rsquo;ll take the big dictionary that&amp;rsquo;s printed above and plot it out with RMSE on the y axis, k on the x axis, and then each colored line is a different model.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import matplotlib.pyplot as plt
% matplotlib inline

for k,v in k_rmse_results_2.items():
    x = list(v.keys())
    y = list(v.values())
    
    plt.plot(x,y)
    plt.xlabel(&#39;k value&#39;)
    plt.ylabel(&#39;RMSE&#39;)
    
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=figure&gt;&lt;img src=/project/Car_Prices/output_27_0.png&gt;&lt;/div&gt;
&lt;p&gt;The pattern you can discern just looking at the numbers becomes clear here when looking at the graph. The best models for any given set of predictors is right around a k of 3-5. Once we start adding more than that, the performance of the model gets worse.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;So, we&amp;rsquo;ve learned a lot about how to run a KNN regression using python, how to tweak paramaters like the number of predictors in a model and the number of neighbors we use, and how to evaluate those models.&lt;/p&gt;
&lt;p&gt;From this, we learned in our simple set of predictions that the most accurate model is using just the two best predictors, engine size and highway miles per gallon, with k set somewhere in the 3-5 range.&lt;/p&gt;
&lt;p&gt;I hope you found this tutorial helpful, and I encourage you to give it a shot for yourself using this dataset, or any other, from UCI&amp;rsquo;s rich machine learning repository!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Does High Economic Inequality, and Low Economic Mobility Threaten, the Relationship Between Income and Happiness?</title>
      <link>/project/mobility_happiness/</link>
      <pubDate>Fri, 05 Oct 2018 00:00:00 -0500</pubDate>
      <guid>/project/mobility_happiness/</guid>
      <description>&lt;p&gt;Myriad past research demonstrates a fairly strong link between money and happiness. That is, people are generally happier when they make more money up to around the $75,000 a year mark 
&lt;a href=&#34;http://www.pnas.org/content/pnas/107/38/16489.full.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(e.g., Kahneman &amp;amp; Deaton, 2010)&lt;/a&gt;. However, one possible threat to this relationship is the level of economic inequality. Really, one could imagine this relationship going in either directions. On one hand, it seems intuitive that money has more happiness purchasing-power when your immediate community is highly unequal. In this case, having a lot of money could make you more satisfied to have &amp;lsquo;made it.&amp;rsquo; On the other hand, it could be extremely uncomfortable to be on the top of the economic ladder when poverty is so readily apparent.&lt;/p&gt;
&lt;p&gt;I tested this question with a set of multilevel models using four different datasets, which can be found 
&lt;a href=&#34;https://github.com/dwiwad/Inequality-Mobility-Income-and-Happiness/tree/master/Data&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;survey_data.csv&lt;/strong&gt;; This dataset contains 1,441 survey responses from two qualtrics national panels. The key individual variables here are happiness, economic quintile, age, political ideology, and location (latitude and longitude). We collected these data in our lab as part of larger projects exploring the psychological correlates of perceived economic mobility.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ACS_14_5YR_B19083&lt;/strong&gt;; this dataset is from the United States census and contains two county identifiers (FIPS code and county name), income inequality (Gini) for each county, and the standard error for each Gini coefficient.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;gini.by.state&lt;/strong&gt;; this dataset is also from the United States census and contains two state identifiers (FIPS code and state name), income inequality (Gini) for each state, and the standard error for each Gini coefficient.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;mobility.by.county&lt;/strong&gt;; this dataset is from the Harvard Mobility Project and contains a measure of income mobility, as well as various population demographics, for each county. The measure I will be using, absolute upward mobility, quantifies the average income percentile for a child whose parents were in the 25th percentile. So, for example, if a county has an absolute upward mobility value of 40 this means that the children of parents who were in the 25th percentile of the income distribution ended up, on average, in the 40th percentile.&lt;/p&gt;
&lt;p&gt;So, some of the data was data we had collected in the past and some of the data came from established sources. The first thing I did was take a quick look at where our participants were in the United  States.&lt;/p&gt;
&lt;div class=figure&gt;&lt;img src=/project/Mobility_Happiness/geo_locate.png&gt;&lt;/div&gt;
&lt;p&gt;So, we can see that the participants are pretty spread out across the United States, with a bit of a dearth in the central United States; most participants seem to be in the Eastern U.S. I used this geolocation data to assign each participant the county in which they live. I will spare you the nitty-gritty details of the multilevel modeling, but if you are so inclined you can find everything 
&lt;a href=&#34;https://github.com/dwiwad/Inequality-Mobility-Income-and-Happiness/blob/master/Markdown%20Docs/MLM_Comprehensive_Exam.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What I found was that, in line with past research, personal income (as measured by which income quintile the person reports being in) was a very strong predictor of happiness. In accounting for all the individual (age, gender, political ideology) and county-level (inequality) factors, it income was the only significant determinant of happiness. While I didn&amp;rsquo;t observe a significant interaction between income and happiness, suggesting that there could be a relationship here. But what does that relationship actually look like?&lt;/p&gt;
&lt;p&gt;In order to take a look at this, I did a quartile split on income inequality and binned participants into four categories: extremely low inequality (gini less than .43), low inequality (gini between .43 and .45), high inequality (gini more than .45 and less than.48), and very  high inequality (gini more than .48). Then, I plotted out the simple relationshp between income quintile and happiness in each of these inequality categories.&lt;/p&gt;
&lt;div class=figure&gt;&lt;img src=/project/Mobility_Happiness/ineq_hap_simp.png&gt;&lt;/div&gt;
&lt;p&gt;What you can see here pretty clearly is that the slope of the relationship in counties with less inequality (the green and orange lines) is steeper than in counties with more inequality (the purple and pink lines). That is to say, money seems to have more &amp;ldquo;happiness purchasing power&amp;rdquo; when people live in more equal communities. Just to look at this in another way, here are the data plotted as actual means instead of over simplified regression lines.&lt;/p&gt;
&lt;div class=figure&gt;&lt;img src=/project/Mobility_Happiness/ineq_hap.png&gt;&lt;/div&gt;
&lt;p&gt;The above presented data show that the increase we get in happiness from having more money is diminished in places with higher inequality. One possible reason for this is simply exposure to inequality through poverty. Looking only at the people who reported being in the fifth quintile, you can see that happiness is the lowest in the high and extremely high inequality places. It’s possible that in these places the high income people are exposed to more poverty, and thus feel an increased sense of wealth guilt, leading to a dampened general happiness.&lt;/p&gt;
&lt;p&gt;This is only one possible explanation and uncovering the mechanism here requires significant further exploration. For now, I’m going to just explore the data again, this time looking at the level of absolute upward mobility present in a county, instead of inequality.&lt;/p&gt;
&lt;h2 id=&#34;income-and-happiness-by-county-upward-mobility&#34;&gt;Income and Happiness by County Upward Mobility&lt;/h2&gt;
&lt;p&gt;One might suspect an interaction here such that the relationship between income and happiness is stronger in places with low mobility, perhaps as a sort of dissonance mechanism. That is, when one cannot move up the income ladder they rationalize and are thus happier with their level of income, regardless. Specifically, I would think that high income people are equally happy regardless of the level of mobility, but as mobility drops the baseline level of happiness for those in lower quintiles rises. Same with the previous analysis, I&amp;rsquo;m going to spare you all the nitty-gritty modeling details here and just present the main trends.&lt;/p&gt;
&lt;div class=figure&gt;&lt;img src=/project/Mobility_Happiness/mob_hap_simp.png&gt;&lt;/div&gt;
&lt;p&gt;This actually doesnt look all that different from the inequality version of the graph, but here there is no interaction whatsoever. The slopes are all equal. Let’s take a quick look at the graph of the actual data, instead of the regression lines:&lt;/p&gt;
&lt;div class=figure&gt;&lt;img src=/project/Mobility_Happiness/mob_hap.png&gt;&lt;/div&gt;
&lt;p&gt;Looking at this graph versus the graph with county inequality makes it clear there really is no interaction here, just as the MLM data show. These models suggest that the relationship between income and happiness may indeed be influenced by the level of inequality present in the county one lives. Specifically, income has greater happiness purchasing power when you live in a more equal society. Perhaps this is due to the decreased availability of visible poverty and inequality, leading to a lower sense of wealth guilt among those living in the higher quintiles. On the other hand, it is also possible that in areas with lower inequality do not suffer so much from the middle class being washed out, thus having a higher income means one’s purchasing power is higher and can live relatively better off compared with someone of the same income bracket in a high-inequality city, where their money potentiall has less purchasing power.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In sum, across this analysis I: (a) cleaned and combined four separate datasets into one useable dataset with individual and county level information, (b) ran a series of multilevel models exploring the interaction of county-level data and individual level relationships, and (C) unpacked these interactions with concise data visualization. Within the analyses, I first replicated a long-standing effect showing that higher wealth is related to higher happiness, overall. I then built upon this, showing that there appears to be a modest interaction between the level of inequality where one lives and the strength of the money-happiness relationship. Particularly, it appears that the happiness-purchasing power of money is greater when one lives in a more equal county. Lastly, I found that the level of absolute upward mobility in a county does not change the nature of the money-happiness relationship&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/terms/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visualizing the Tour De France</title>
      <link>/project/tdf_speed/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0500</pubDate>
      <guid>/project/tdf_speed/</guid>
      <description>&lt;p&gt;In this short post I&amp;rsquo;m going to do the first set of two visualizations exploring data regarding the grand tours that I pulled from Wikipedia. Specifically, here I&amp;rsquo;m going to look at a couple elements of the Tour de France over it&amp;rsquo;s entire 114 year history. Namely, I&amp;rsquo;m going to look at the length of the Tour, the average speed of the winner for each edition, their total winning time, and the margin that they won by.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m not intending to do any inferential analyses, but what I&amp;rsquo;m expecting to see is that the Tour is getting faster and shorter, and is being won on smaller margins as time goes on. I&amp;rsquo;m going to hide all of the code in this particular notebook, but I will display some of the raw data and explain the process as I go along just so you can see where I started and where I got to, and then what those data actually look like. If you are interested in the more technical aspects of how I did all of these analyses, there is a seperate jupyter notebook in the repository I put up on github for this particular project 
&lt;a href=&#34;https://github.com/dwiwad/Analyzing-the-Grand-Tours&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. These notebooks have more detailed information on what I did step by step, including all of the code.&lt;/p&gt;
&lt;p&gt;With that, let&amp;rsquo;s get right into the data!&lt;/p&gt;
&lt;h2 id=&#34;tour-de-france-winners-data&#34;&gt;Tour de France Winners Data&lt;/h2&gt;
&lt;p&gt;I grabbed these data from the wikipedia page for Tour GC winners, which can be found here on 
&lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_Tour_de_France_general_classification_winners&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the wikipedia page for Tour de France GC Winners.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s take a quick look at these raw data; what does it look like once scraped from wikipedia and cleaned a little bit? Here&amp;rsquo;s the first and last five rows (i.e., the first and most recent five Tour  winners):&lt;/p&gt;
&lt;div class=figure&gt;&lt;img src=/project/tdf_speed/tour_early.png&gt;&lt;/div&gt;
&lt;div class=figure&gt;&lt;img src=/project/tdf_speed/tour_late.png&gt;&lt;/div&gt;
&lt;p&gt;We&amp;rsquo;ve got a lot of interesting information in this table, including the winner, their team, the number of stage wins, etc. However, given that I&amp;rsquo;m focusing here on speed of the tour, I&amp;rsquo;m going to pull out all the information I need and put it into one smaller new table. That is, I&amp;rsquo;ll pull out the columns for distance, time, and margin.&lt;/p&gt;
&lt;p&gt;From this, I&amp;rsquo;ll calculate a new column, average speed, which is simply the total distance divided by the winning time. Here&amp;rsquo;s what the new cleaned up data look like:&lt;/p&gt;
&lt;div class=figure&gt;&lt;img src=/project/tdf_speed/tour_clean_head.png alt=&#34;&#34; width=&#34;65%&#34; height=&#34;65%&#34;/&gt;&lt;/div&gt;
&lt;div class=figure&gt;&lt;img src=/project/tdf_speed/tour_clean_tail.png alt=&#34;&#34; width=&#34;65%&#34; height=&#34;65%&#34;/&gt;&lt;/div&gt;
&lt;p&gt;So here is the data that we&amp;rsquo;re going to work with from now on. We&amp;rsquo;ve got winning time in hours, total distance in kilometers, winning margin in seconds, and then average speed in kilometers per hour. Let&amp;rsquo;s take a look now, and see how things have changed over time.&lt;/p&gt;
&lt;div class=figure&gt;&lt;img src=/project/tdf_speed/all_in_one.png&gt;&lt;/div&gt;
&lt;p&gt;There&amp;rsquo;s tons of interesting things going on here! One thing to note first, is the blue bars correspond to missing data - as in, years where there was no Tour de France, or the Tour was structured differently. First, between 1905 and 1912 the Tour was scored on points so there is no distance and time data there. Second (and third), the Tour was not run during either of the World Wars. So, brushing over that let&amp;rsquo;s dive into the data.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll focus first on the top and bottom graphs, because most of the interesting stuff, in my opinion, is in the middle. First, the Tour has been getting shorter since right around WW I. This isn&amp;rsquo;t entirely surprising because back in the early 20th century the Tour was envisioned as a savage race for only the hardest men, where only one man would actually make it to the end. So, over the years the Tour has gotten shorter but still a formidable distance.&lt;/p&gt;
&lt;p&gt;Second, the winning margin was huge back when the Tour was inhumanely difficult - the margin was in the realm of hours. However, since the 1950s the winning margin has been in the realm of minutes or seconds. We&amp;rsquo;ll dive a bit deeper into this later on.&lt;/p&gt;
&lt;p&gt;Lastly, the overall winning time and average speed. This is where stuff gets a bit more interesting! The overall winning time has been getting lower and lower, which makes sense given the tour has gotten shorter and faster. The tour has been getting consistently faster over the years, even over just the last few decades. In fact, the average speed was still around 32kmh in the early 1970s and was over 40 kmh the last few years. Thats nearly a 20% increase in average speed over four decades. Average speed seemed to increase pretty sharply from the 1960s to the early 2000s, but has seemed pretty consistent since then. I did, however, notice some interesting blips in the 1990s and 2000s. Let&amp;rsquo;s dive a little bit deeper in the speed data for those years.&lt;/p&gt;
&lt;div class=figure&gt;&lt;img src=/project/tdf_speed/zoomed.png&gt;&lt;/div&gt;
&lt;p&gt;When we zoom in on the last 46 years (1971-2017) we can see this pattern a little bit more clearly. When zoomed in, the pattern of the Tour getting faster looks a little bit less remarkable, but I think it&amp;rsquo;s still quite amazing when you unpack what these numbers are actually showing. I&amp;rsquo;m going to focus on the average speed column.&lt;/p&gt;
&lt;p&gt;While they don&amp;rsquo;t look like huge peaks, you&amp;rsquo;ll notice that the year of the Festina Affair and the last year of Lance (one year before Operacion Puerto) are the fastest edtions of the tour in the last half century - this is not over a trivial time frame. Even when you think about the advancements in bike, kit, and athlete training technology over the last decade, Lance in his last year was still faster than the current pros who have ten extra years of engineering underneath them.&lt;/p&gt;
&lt;p&gt;The other bit, is that even though the slope of the average speed line doesn&amp;rsquo;t look crazy - it&amp;rsquo;s actually quite steep. The average speed of the Tour has increased by about 6 km/h since the 1970s, which is an increase of about 17%. All this while the tour has remained relatively consistent in its distance of about 3,500 km.&lt;/p&gt;
&lt;p&gt;It would be nice to be able to factor in total elevation data (maybe they&amp;rsquo;re faster now because they&amp;rsquo;re climbing less), but I can&amp;rsquo;t find these data anywhere.&lt;/p&gt;
&lt;p&gt;The general pattern seems to me to be twofold: (1) The tour is getting faster and faster and (2) There were relatively big drops in average speed after each major doping scandal, followed by slow and steady increases in speed (including over the last twelve years).&lt;/p&gt;
&lt;p&gt;That being said, I don&amp;rsquo;t think the Tour will actually get substantially faster without drastic changes to the route or UCI rules. For instance, I can&amp;rsquo;t see the average speed hitting the mid-forties.&lt;/p&gt;
&lt;p&gt;Lastly, I&amp;rsquo;m going to zoom in a bit on the winning margins.&lt;/p&gt;
&lt;div class=figure&gt;&lt;img src=/project/tdf_speed/margin.png&gt;&lt;/div&gt;
&lt;p&gt;When we zoom in on the winning margins, we can see there is still a slight slope down. The time gap to the winner is getting smaller and smaller over time. Again, it doesn&amp;rsquo;t seem like much but the slope of this line goes down from ten minutes in 1971 (~ 600 seconds) to just 54 seconds in 2017. Again, I don&amp;rsquo;t think there&amp;rsquo;s really anywhere to go from here though. I suspect we will just continue to see the Tour being won on margins of less than a minute for the foreseeable future, unless there are major shakeups to the UCI&amp;rsquo;s rules.&lt;/p&gt;
&lt;h2 id=&#34;limitations&#34;&gt;Limitations&lt;/h2&gt;
&lt;p&gt;The biggest limitation of these basic visualizations, particularly the data about average speed, is that I would like to factor in the elevation gain for a given tour. The speed info is hard to interpret without it. For instance, a tour with 10 flat sprinters stages is likely to be faster, on average, than a tour with only 3. This doesn&amp;rsquo;t mean riders are getting faster overall, it just means the structure of the Tour was weighted towards faster stages. Unfortunately, I cannot find these data anywhere. I think we can assume though, that changes in the structure of the Tour don&amp;rsquo;t explain all changes in speed over the last few decades, where the race is very much a climbers race.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Academic: the website builder for Hugo</title>
      <link>/post/getting-started/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/post/getting-started/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 &lt;em&gt;widgets&lt;/em&gt;, &lt;em&gt;themes&lt;/em&gt;, and &lt;em&gt;language packs&lt;/em&gt; included!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://academic-demo.netlify.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Check out the latest &lt;strong&gt;demo&lt;/strong&gt;&lt;/a&gt; of what you&amp;rsquo;ll get in less than 10 minutes, or 
&lt;a href=&#34;https://sourcethemes.com/academic/#expo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;view the &lt;strong&gt;showcase&lt;/strong&gt;&lt;/a&gt; of personal, project, and business sites.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;👉 
&lt;a href=&#34;#install&#34;&gt;&lt;strong&gt;Get Started&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;📚 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;View the &lt;strong&gt;documentation&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;💬 
&lt;a href=&#34;https://discourse.gohugo.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Ask a question&lt;/strong&gt; on the forum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;👥 
&lt;a href=&#34;https://spectrum.chat/academic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Chat with the &lt;strong&gt;community&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;🐦 Twitter: 
&lt;a href=&#34;https://twitter.com/source_themes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@source_themes&lt;/a&gt; 
&lt;a href=&#34;https://twitter.com/GeorgeCushen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@GeorgeCushen&lt;/a&gt; 
&lt;a href=&#34;https://twitter.com/search?q=%23MadeWithAcademic&amp;amp;src=typd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;#MadeWithAcademic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;💡 
&lt;a href=&#34;https://github.com/gcushen/hugo-academic/issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Request a &lt;strong&gt;feature&lt;/strong&gt; or report a &lt;strong&gt;bug&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;⬆️ &lt;strong&gt;Updating?&lt;/strong&gt; View the 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/update/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Update Guide&lt;/a&gt; and 
&lt;a href=&#34;https://sourcethemes.com/academic/updates/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Release Notes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;❤️ &lt;strong&gt;Support development&lt;/strong&gt; of Academic:
&lt;ul&gt;
&lt;li&gt;☕️ 
&lt;a href=&#34;https://paypal.me/cushen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Donate a coffee&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;💵 
&lt;a href=&#34;https://www.patreon.com/cushen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Become a backer on &lt;strong&gt;Patreon&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;🖼️ 
&lt;a href=&#34;https://www.redbubble.com/people/neutreno/works/34387919-academic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Decorate your laptop or journal with an Academic &lt;strong&gt;sticker&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;👕 
&lt;a href=&#34;https://academic.threadless.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wear the &lt;strong&gt;T-shirt&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;👩‍💻 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/contribute/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Contribute&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure id=&#34;figure-academic-is-mobile-first-with-a-responsive-design-to-ensure-that-your-site-looks-stunning-on-every-device&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/academic.png&#34; data-caption=&#34;Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.&#34;&gt;


  &lt;img src=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/academic.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Key features:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Page builder&lt;/strong&gt; - Create &lt;em&gt;anything&lt;/em&gt; with 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/page-builder/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;widgets&lt;/strong&gt;&lt;/a&gt; and 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;elements&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Edit any type of content&lt;/strong&gt; - Blog posts, publications, talks, slides, projects, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create content&lt;/strong&gt; in 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Markdown&lt;/strong&gt;&lt;/a&gt;, 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/jupyter/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Jupyter&lt;/strong&gt;&lt;/a&gt;, or 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/install/#install-with-rstudio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;RStudio&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plugin System&lt;/strong&gt; - Fully customizable 
&lt;a href=&#34;https://sourcethemes.com/academic/themes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;color&lt;/strong&gt; and &lt;strong&gt;font themes&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Display Code and Math&lt;/strong&gt; - Code highlighting and 
&lt;a href=&#34;https://en.wikibooks.org/wiki/LaTeX/Mathematics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LaTeX math&lt;/a&gt; supported&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integrations&lt;/strong&gt; - 
&lt;a href=&#34;https://analytics.google.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Analytics&lt;/a&gt;, 
&lt;a href=&#34;https://disqus.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Disqus commenting&lt;/a&gt;, Maps, Contact Forms, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Beautiful Site&lt;/strong&gt; - Simple and refreshing one page design&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Industry-Leading SEO&lt;/strong&gt; - Help get your website found on search engines and social media&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Media Galleries&lt;/strong&gt; - Display your images and videos with captions in a customizable gallery&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mobile Friendly&lt;/strong&gt; - Look amazing on every screen with a mobile friendly version of your site&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-language&lt;/strong&gt; - 15+ language packs including English, 中文, and Português&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-user&lt;/strong&gt; - Each author gets their own profile page&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Privacy Pack&lt;/strong&gt; - Assists with GDPR&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stand Out&lt;/strong&gt; - Bring your site to life with animation, parallax backgrounds, and scroll effects&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;One-Click Deployment&lt;/strong&gt; - No servers. No databases. Only files.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;p&gt;Academic comes with &lt;strong&gt;automatic day (light) and night (dark) mode&lt;/strong&gt; built-in. Alternatively, visitors can  choose their preferred mode - click the sun/moon icon in the top right of the 
&lt;a href=&#34;https://academic-demo.netlify.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Demo&lt;/a&gt; to see it in action! Day/night mode can also be disabled by the site admin in &lt;code&gt;params.toml&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/themes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Choose a stunning &lt;strong&gt;theme&lt;/strong&gt; and &lt;strong&gt;font&lt;/strong&gt;&lt;/a&gt; for your site. Themes are fully 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/customization/#custom-theme&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;customizable&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;ecosystem&#34;&gt;Ecosystem&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;
&lt;a href=&#34;https://github.com/sourcethemes/academic-admin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic Admin&lt;/a&gt;:&lt;/strong&gt; An admin tool to import publications from BibTeX or import assets for an offline site&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;
&lt;a href=&#34;https://github.com/sourcethemes/academic-scripts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic Scripts&lt;/a&gt;:&lt;/strong&gt; Scripts to help migrate content to new versions of Academic&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;install&#34;&gt;Install&lt;/h2&gt;
&lt;p&gt;You can choose from one of the following four methods to install:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/install/#install-with-web-browser&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;one-click install using your web browser (recommended)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/install/#install-with-git&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;install on your computer using &lt;strong&gt;Git&lt;/strong&gt; with the Command Prompt/Terminal app&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/install/#install-with-zip&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;install on your computer by downloading the &lt;strong&gt;ZIP files&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/install/#install-with-rstudio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;install on your computer with &lt;strong&gt;RStudio&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/get-started/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;personalize and deploy your new site&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;updating&#34;&gt;Updating&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/update/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;View the Update Guide&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Feel free to &lt;em&gt;star&lt;/em&gt; the project on 
&lt;a href=&#34;https://github.com/gcushen/hugo-academic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Github&lt;/a&gt; to help keep track of 
&lt;a href=&#34;https://sourcethemes.com/academic/updates&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;updates&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;license&#34;&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright 2016-present 
&lt;a href=&#34;https://georgecushen.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;George Cushen&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Released under the 
&lt;a href=&#34;https://github.com/gcushen/hugo-academic/blob/master/LICENSE.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MIT&lt;/a&gt; license.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hello R Markdown</title>
      <link>/post/2015-07-23-r-rmarkdown/</link>
      <pubDate>Thu, 23 Jul 2015 21:13:14 -0500</pubDate>
      <guid>/post/2015-07-23-r-rmarkdown/</guid>
      <description>


&lt;div id=&#34;r-markdown&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R Markdown&lt;/h1&gt;
&lt;p&gt;This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see &lt;a href=&#34;http://rmarkdown.rstudio.com&#34; class=&#34;uri&#34;&gt;http://rmarkdown.rstudio.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can embed an R code chunk like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(cars)
##      speed           dist       
##  Min.   : 4.0   Min.   :  2.00  
##  1st Qu.:12.0   1st Qu.: 26.00  
##  Median :15.0   Median : 36.00  
##  Mean   :15.4   Mean   : 42.98  
##  3rd Qu.:19.0   3rd Qu.: 56.00  
##  Max.   :25.0   Max.   :120.00
fit &amp;lt;- lm(dist ~ speed, data = cars)
fit
## 
## Call:
## lm(formula = dist ~ speed, data = cars)
## 
## Coefficients:
## (Intercept)        speed  
##     -17.579        3.932&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;including-plots&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Including Plots&lt;/h1&gt;
&lt;p&gt;You can also embed plots. See Figure &lt;a href=&#34;#fig:pie&#34;&gt;1&lt;/a&gt; for example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mar = c(0, 1, 0, 1))
pie(
  c(280, 60, 20),
  c(&amp;#39;Sky&amp;#39;, &amp;#39;Sunny side of pyramid&amp;#39;, &amp;#39;Shady side of pyramid&amp;#39;),
  col = c(&amp;#39;#0292D8&amp;#39;, &amp;#39;#F7EA39&amp;#39;, &amp;#39;#C4B632&amp;#39;),
  init.angle = -50, border = NA
)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:pie&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/post/2015-07-23-r-rmarkdown_files/figure-html/pie-1.png&#34; alt=&#34;A fancy pie chart.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: A fancy pie chart.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
